{"cells":[{"metadata":{"_cell_guid":"3ca1b096-3957-49ed-9cd6-d8a1f8f034f7","_uuid":"41f59e435a7e791d26615d73d255a2b2eb0cf06e"},"cell_type":"markdown","source":"* [Day 1: Reading in common data file formats: .json, .txt and .xlsx](https://www.kaggle.com/rtatman/data-cleaning-challenge-json-txt-and-xls/)\n* [Day 2: Filling in missing values ](https://www.kaggle.com/rtatman/data-cleaning-challenge-imputing-missing-values/)\n* [Day 3: Identifying & handling outliers](https://www.kaggle.com/rtatman/data-cleaning-challenge-outliers/)\n* [Day 4: Removing duplicate records](https://www.kaggle.com/rtatman/data-cleaning-challenge-deduplication/)\n* [Day 5: Cleaning numbers (percentages, money, dates and times)](https://www.kaggle.com/rtatman/data-cleaning-challenge-cleaning-numeric-columns/)\n    \n___\n\nWelcome to Day 5 of the 5-Day Data Challenge! (Can you believe it's the last day already?) Today, we're going to be learning how to clean up columns with dates and numbers in them that R doesnâ€™t realize are dates or numbers. In particular, we'll learn how to remove symbols like \"%\" or \"$\", and how to get R to correctly parse dates so you can do things like plot days in order. \n\nI'll start by introducing each concept or technique, and then you'll get a chance to apply it with an exercise (look for the **Your turn!** section). Ready? Let's get started!\n___\n\n**Kernel FAQs:**\n\n* **How do I get started?**   To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n* **How do I run the code in this notebook?** Once you fork the notebook, it will open in the notebook editor. From there you can write code in any code cell (the ones with the grey background) and run the code by either 1) clicking in the code cell and then hitting CTRL + ENTER or 2) clicking in the code cell and the clicking on the white \"play\" arrow to the left of the cell. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\n* **How do I save my work?** Any changes you make are saved automatically as you work. You can run all the code in your notebook and save a static version by hitting the blue \"Commit & Run\" button in the upper right hand corner of the editor. \n\n* **How can I find my notebook again later?** The easiest way is to go to your user profile (https://www.kaggle.com/replace-this-with-your-username), then click on the \"Kernels\" tab. All of your kernels will be under the \"Your Work\" tab, and all the kernels you've upvoted will be under the \"Favorites\" tab.\n\n___\n"},{"metadata":{"_cell_guid":"181d6445-1524-49cd-971e-af591fe29063","_uuid":"222b8ed8f318bf9108f8f9d2a943a4ddfa25b5e6"},"cell_type":"markdown","source":"# Get our environment set up\n___\n\nAt this point you know the drill: we need to get our libraries and data all read in a ready to go. "},{"metadata":{"_cell_guid":"d1e2d1b4-1b4d-4d3a-9870-251d65a805bf","_uuid":"d4dc7b6af917e19fa69178b0a8a9fbcc41fd2c33","_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"# libraries we'll need\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# read in the data we'll need\nlistings <- read_csv(\"../input/boston/listings.csv\")\nhospital_charges <- read_csv(\"../input/inpatient-hospital-charges/inpatientCharges.csv\") %>%\n    janitor::clean_names() # clean up column names, with clean_names() from the janitor package\ndrone_strikes <- read_csv(\"../input/pakistandroneattacks/PakistanDroneAttacksWithTemp Ver 9 (October 19, 2017).csv\") %>%\n    janitor::clean_names() # clean up column names\n# remove the last row (has totals in it)\ndrone_strikes <- drone_strikes[-nrow(drone_strikes),] \nmass_shootings <- read_csv(\"../input/us-mass-shootings-last-50-years/Mass Shootings Dataset Ver 5.csv\")%>%\n    janitor::clean_names() # clean up column names","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a6f0dd7-d65e-4aa4-8a60-aa0b2137a45e","_uuid":"24a50c381d4dff8cffcbbc13de2c3c594f373b3b"},"cell_type":"markdown","source":"# Removing in non-numeric characters\n___\n\nSometimes you'll get a dataset and find that someone has helpfully added percentage signs, dollar signs or other non-numeric symbols that tell you the units of the data you're working with. While this is great when you're looking at the data, it can lead to problems when you're trying to work with it in R. This is because when you read in a dataframe in R, it makes a guess about what data type each column is by looking at what is in that column. And if it runs in to any characters that aren't numbers in your column, it will play it safe and say that the datatype is \"character\" rather than \"numeric\". This means that in order to actually do any math with that column, you need some way to remove any non-numeric characters.\n\nIf you have tried to solve this problem in the past, you may have come across people suggesting that you use regular expressions. While I'm a big fan of regular expressions (I use one to get days of the week later on in this kernel), I would *strongly* advise you to steer clear of them in data cleaning unless you have no other choice. Why?\n\n* **Regular expressions are brittle.** Since they rely on matching a very specific set of characters in a specific order, if you get new data later that's slightly different your regular expressions won't work. And if you haven't had to debug regular expressions previously, count yourself lucky: it's a huge pain.\n* **Regular expressions are hard to write & read.** If you've worked with regular expressions before, you know that they are hard to get right! They're also very hard to read: can you tell what this is supposed at first glance? `^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$`.  (It's [a Roman Numeral finder](https://stackoverflow.com/a/800868/9403317), in case you were wondering.) If something is both hard to write and hard to read that means you and your team will spend more time on it than you need to, especially if there's another option.\n\nInstead, the option I'd recommend is `parse_number()` from the readr package by Jim Hester. This is one of the things we load in with `library(tidyverse)`. `parse_number()` can handle most of the common ways that numbers are presented and neatly tidies up the non-numeric characters and changes the class of the resulting object:"},{"metadata":{"_cell_guid":"5629ddfa-af17-4e36-b65b-6400b172211c","_uuid":"8467703a05c2e45c67e9de23eca1dec40676b2b2","trusted":false},"cell_type":"code","source":"# character vector of numbers\nto_parse <- c(100, \"10,000\", \"%100\", \"$50\")\n\n# check to make sure it's numeric\nprint(\"Class before:\")\nclass(to_parse)\n\n# parse numbers\nparsed_numbers <- parse_number(to_parse)\n\n# check class\nprint(\"Class after:\")\nclass(parsed_numbers)\n\n# see what it looks like now\nparsed_numbers","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1880231c-7940-475c-8a65-c8e682e9670c","_uuid":"9b99be0622dc7c27bcee34da2d5169885dae028c"},"cell_type":"markdown","source":"Of  course, it's easy to use with a toy example, by how well does it extend to real datasets? Pretty well, in my experience! \n\nFirst, I like to pull out all the columns that are \"character\" class and look at them. (I focus on character columns because I don't need to re-parse the numeric columns that were parsed correctly the first time.)"},{"metadata":{"_cell_guid":"235bfc41-2691-4129-aa83-09d0e4db05bd","_uuid":"bede04b450448bddd0263e648fc2106ae9477447","trusted":false},"cell_type":"code","source":"# get only columns with the data type \"character\" \ncharacter_columns <- hospital_charges[, sapply(hospital_charges, class) == \"character\"]\n\n# look at these columns\nstr(character_columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35a26f65-2c6c-45cb-82fb-871b9881ccd6","_uuid":"31eeb96dfcb85c571ea12e6901c1b8b885344791"},"cell_type":"markdown","source":"Looking at these columns, it seems like only the last three have been parsed incorrectly: each of them should actually be numeric. My next step is to select just those columns and parse each of them. "},{"metadata":{"_cell_guid":"31dfa98f-43f0-4b2f-8fbf-137f89ddb267","_uuid":"6e096f8ed1d70a6d51f4220e8f75c35febf59211","trusted":false},"cell_type":"code","source":"# select columns with \"charge\" or \"pay\" in the name\nmoney_columns <- character_columns %>%\n    select(contains(\"charge\"), contains(\"pay\")) \n\n# parse each of those columns as numeric using sapply()\nmoney_columns_parsed <- sapply(money_columns, parse_number) %>%\n    as_data_frame()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33c8e67a-eff5-4fa3-8a9a-afa0b3db6760","_uuid":"125b12ea047fc04e6eed7351ab5185bb845de109"},"cell_type":"markdown","source":"Finally, I make a new copy of the dataset with the parsed columns. (You may want to avoid making a bunch of copies like this if your dataset is very large, but I like the safety net of not modifying data in place.)"},{"metadata":{"_cell_guid":"61e5f08a-a85f-4999-812c-d7ca0c3116d4","_uuid":"8950a1e0ad433689968494400711e9b353892895","trusted":false},"cell_type":"code","source":"# replace columns with their parsed versions\nhospital_charges_parsed <- hospital_charges %>%\n    # the next line *removes* the columns we selected earlier\n    select(-contains(\"charge\"), -contains(\"pay\")) %>%\n    # add the columns we parsed earlier\n    bind_cols(money_columns_parsed)\n\n# double check that our data types are correct\nstr(hospital_charges_parsed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0f02894-4b66-4e01-9e56-b165b1ad7e32","_uuid":"9675b6dfc18eccca34b586be14ee5d085d9b4be6"},"cell_type":"markdown","source":"And now our numeric columns are actually numeric! From here you can work with them as you would any other numeric values."},{"metadata":{"_cell_guid":"e26ff1e4-7f55-4008-8276-10570385bc24","_uuid":"4137683b840c3fd05e277d88f796d9dfa9935b3a"},"cell_type":"markdown","source":"## Your turn!\n___\n\nTake a look at the `listings` dataset, which contains information on Airbnb listings. You should find quite a few numeric columns read in as characters that need to be parsed. If you're looking for more of a challenge, there are also some logical columns (with 't' and 'f') that have been parsed as characters. Try parsing them using `parse_logical()`. \n\nIf you're looking an extra-tough challenge, try writing a function that identifies which numeric columns might have been mis-parsed as characters and attempts to parse them correctly.  "},{"metadata":{"_cell_guid":"988f39a6-722e-48f2-a28b-d1bbce3b2a42","_uuid":"381da76e16bff8b19c048a38af493648673eac7f","trusted":false},"cell_type":"code","source":"# your code here :)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"754291f5-6fe7-4989-9039-0e96f1573d61","_uuid":"d5c888a1152a43a6d999228860f3e31dfef12937"},"cell_type":"markdown","source":"# Parsing dates & times\n___\n\nSometimes you're lucky and your dates will be in a format that R knows how to handle and will be read in and parsed automatically. Sometimes, however, you'll have to let R know that a certain column contains a date and what the format of that date is. This is known as *parsing* a date. I generally use [the lubridate package](https://cran.r-project.org/web/packages/lubridate/index.html) by Vitalie Spinu and co-authors for parsing dates. These are the four functions I use most often to parse dates in different formats:\n\n* **mdy()**, for dates that are month, day and then year\n* **ymd()**, for dates that are year, month and then day\n*  **dmy()**, for dates that are day, month and then year\n* **ymd_hms()**, for dates that are year, month, day, hour, minute and finally second\n\nOnce a date is parsed, you can easily extract parts of it using functions like month() and year() and plot or analyze it like any other numeric variable. You can learn more about parsing dates [here](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html).\n\nNow that we've got the basics, let's put them into practice. Here are some of the dates in the date column of the `drone_strikes` dataset. "},{"metadata":{"_cell_guid":"4c2d28b6-6304-4c78-ae92-f1476e797b85","_uuid":"5792a5eaca5e209a24d240aa99098ed5dc7ed967","trusted":false},"cell_type":"code","source":"# look at the dates\ndrone_strikes$date[1:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"421c5028-7648-4cc2-b3e3-050b920873a4","_uuid":"8bbea3a4d9244a5bc71f938f7dd30e7ef742c414"},"cell_type":"markdown","source":"So our dates are in the format: day of week, month, day of month, year. Unfortunately, there's no lubridate parsing function for handling the day of the week, so we'll need to strip them. (Don't worry, once our dates are parsed we can get them all back with the `wday()` function.) Here, I've written a function to remove them for us:"},{"metadata":{"_cell_guid":"aa0488f5-36d6-483a-b4aa-2b2318da5ad0","_uuid":"409078916e45e73ff813aee32095d5031aad3b04","trusted":false},"cell_type":"code","source":"# function to remove the day of the week (friday, monday, etc.) & following comma\nremove_dow <- function(column){\n    no_dow <- str_replace_all(column, '[A-Za-z]*day, ', '')\n    return(no_dow)\n}\n\n# test it out\nremove_dow(drone_strikes$date[1:10])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3894187-1d0a-4bc9-aa8b-b99f89a04e29","_uuid":"f7d2a28e9d67801c1a52c3bebff7b8975c2751ed"},"cell_type":"markdown","source":"Now we can use this function to remove our day of the week, then parse the remaining data with the `mdy()` function. If you don't need to remove the days of the week, you can just skip that line."},{"metadata":{"_cell_guid":"d72c6414-9121-4695-ba5f-5026980fa707","_uuid":"6fd27b788bb6273183f4eb83ad9895b86d231d51","trusted":false},"cell_type":"code","source":"# tidy up dates & convert them to date format\ndates <- drone_strikes %>%\n    select(date) %>% # get the \"date\" column\n    mutate(date_formatted = remove_dow(date)) %>% # remove the day of the week\n    mutate(date_formatted = mdy(date_formatted)) # convert to date format\n\n# compare before & after formatting\nhead(dates)\n\n# add formatted dates to our dataframe\ndrone_strikes$date_formatted <- dates$date_formatted","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b9649dd-86e6-4a66-89f0-a90ea078b03c","_uuid":"e907180aaef4eb8b045034151b3347eaee2e3047"},"cell_type":"markdown","source":"And that's all there is to it! You're now ready to start your time series analysis or easily plot your dates using ggplot.\n\n## Your turn!\n___\n\nCorrectly parse the \"date\" column from the mass_shootings dataset. Print some of the unconverted & converted dates using the head() function to compare them."},{"metadata":{"_cell_guid":"b248cb67-c5f6-4628-b2f3-f906053c5043","_uuid":"5fc69db8bb6c2754b3a488cfb991336323dd6646","trusted":false},"cell_type":"code","source":"# your code goes here :)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fdcdcff6-41d1-429f-b323-d588ead68304","_uuid":"b623103b3f44142047f12d6bc645695ac4704473"},"cell_type":"markdown","source":"# And that's it, you've completed the whole challenge!\n____\n\nCongrats, you've finished the entire 5-Day Challenge on data cleaning with R! I hope you learned lots of helpful tips and tricks that you can apply in your work further down the line. :)\n\nIf you're looking for more content, try checking out [the other 5-Day Challenges](https://www.kaggle.com/rtatman/list-of-5-day-challenges/) or some of the great content we have on the [Kaggle Learn page](https://www.kaggle.com/learn/overview). If you're looking for more practice with data cleaning specifically, I'd recommend picking a new dataset ([maybe one of these](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=all&filetype=all&license=all&tagids=13202)), getting to know it (mainly doing a lot of visualizations) and then making the changes you need to use it for modelling or analysis. "}],"metadata":{"kernelspec":{"display_name":"R","name":"ir","language":"R"},"language_info":{"mimetype":"text/x-r-source","version":"3.4.2","pygments_lexer":"r","name":"R","codemirror_mode":"r","file_extension":".r"}},"nbformat":4,"nbformat_minor":1}